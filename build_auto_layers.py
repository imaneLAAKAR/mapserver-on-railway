# build_auto_layers.py
import os, re, json, requests
import os

SUPABASE_URL  = os.environ.get("SUPABASE_URL")
BUCKET        = os.environ.get("SUPABASE_BUCKET")
SERVICE_KEY   = os.environ.get("SUPABASE_SERVICE_KEY")

# === RENSEIGNE CES 3 VARIABLES D'ENV (ou mets des valeurs ici) ===
SUPABASE_URL  = os.environ.get("SUPABASE_URL", "https://sdbgbkjlzfmowvowtfns.supabase.co")
BUCKET        = os.environ.get("test", "public")  # nom du bucket
SERVICE_KEY   = os.environ.get("eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNkYmdia2psemZtb3d2b3d0Zm5zIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NTI2MjAxNCwiZXhwIjoyMDcwODM4MDE0fQ.OVhqlMtr4fAYL56Y5sH_06R3XWYhF6N_gDcoX4lRqUU")  # clé service (recommandé)

# Dossiers "logiques" dans le bucket
VECT_PREFIX = f"{BUCKET}/vectors"
RAST_PREFIX = f"{BUCKET}/raster"

# Base publique si bucket public
PUBLIC_BASE = f"{SUPABASE_URL}/storage/v1/object/public"
# Sinon, si bucket privé et que tu as un proxy (ex: https://ton-domaine/supa),
# mets PUBLIC_BASE = "https://ton-domaine/supa"

HEADERS = {}
if SERVICE_KEY:  # utile même pour buckets publics afin de lister
    HEADERS = {"Authorization": f"Bearer {SERVICE_KEY}", "apikey": SERVICE_KEY}

def list_folder(prefix: str):
    url = f"{SUPABASE_URL}/storage/v1/object/list/{prefix}"
    r = requests.get(url, headers=HEADERS, params={"limit":1000})
    r.raise_for_status()
    items = r.json()
    return [i for i in items if not i.get("metadata",{}).get("isFolder")]

def is_vector(name: str):
    n = name.lower()
    return n.endswith(".zip") or n.endswith(".gpkg") or n.endswith(".geojson")

def is_raster(name: str):
    n = name.lower()
    return n.endswith(".tif") or n.endswith(".tiff") or n.endswith(".cog")

def safe_name(s: str):
    base = os.path.splitext(os.path.basename(s))[0]
    base = re.sub(r"[^a-zA-Z0-9_]+", "_", base)
    return base[:60] or "layer"

def write_layers(vectors, rasters):
    out_map = []
    out_json = []

    out_map.append("# Auto-generated by build_auto_layers.py\n")

    # --- rasters (COG/TIF) ---
    for key in rasters:
        name = safe_name(key)
        url  = f"{PUBLIC_BASE}/{key}"
        out_map.append(f"""
LAYER
  NAME "{name}"
  TYPE RASTER
  STATUS OFF
  DATA "/vsicurl/{url}"
  PROCESSING "RESAMPLE=AVERAGE"
  METADATA "wms_title" "{name}" END
END
""")
        out_json.append({"name": name, "kind": "raster", "wms_layer": name})

    # --- vecteurs ---
    for key in vectors:
        name = safe_name(key)
        lower = key.lower()
        if lower.endswith(".zip"):
            shp = os.path.splitext(os.path.basename(key))[0] + ".shp"
            url = f"{PUBLIC_BASE}/{key}"
            out_map.append(f"""
LAYER
  NAME "{name}"
  TYPE POLYGON
  STATUS ON
  CONNECTIONTYPE OGR
  CONNECTION "/vsizip//vsicurl/{url}"
  DATA "{shp}"
  PROJECTION "init=epsg:4326" END
  METADATA "wms_title" "{name}" "wfs_enable_request" "*" "gml_include_items" "all" END
  CLASS STYLE COLOR 240 248 255 OUTLINECOLOR 0 100 220 END END
END
""")
        elif lower.endswith(".gpkg"):
            url = f"/vsicurl/{PUBLIC_BASE}/{key}"
            # on suppose que le nom de la couche interne == nom du fichier (recommandé)
            out_map.append(f"""
LAYER
  NAME "{name}"
  TYPE POLYGON
  STATUS ON
  CONNECTIONTYPE OGR
  CONNECTION "{url}"
  DATA "{name}"
  PROJECTION "init=epsg:4326" END
  METADATA "wms_title" "{name}" "wfs_enable_request" "*" "gml_include_items" "all" END
  CLASS STYLE COLOR 240 248 255 OUTLINECOLOR 0 100 220 END END
END
""")
        else:  # .geojson
            url = f"/vsicurl/{PUBLIC_BASE}/{key}"
            out_map.append(f"""
LAYER
  NAME "{name}"
  TYPE POLYGON
  STATUS ON
  CONNECTIONTYPE OGR
  CONNECTION "{url}"
  PROJECTION "init=epsg:4326" END
  METADATA "wms_title" "{name}" "wfs_enable_request" "*" "gml_include_items" "all" END
  CLASS STYLE COLOR 240 248 255 OUTLINECOLOR 0 100 220 END END
END
""")
        out_json.append({"name": name, "kind": "vector", "wms_layer": name, "wfs_layer": name})

    # écrire fichiers
    os.makedirs("mapfiles", exist_ok=True)
    with open("mapfiles/auto_layers.map", "w", encoding="utf-8") as f:
        f.write("\n".join(out_map))
    with open("mapfiles/layers.json", "w", encoding="utf-8") as f:
        json.dump({"layers": out_json}, f, ensure_ascii=False, indent=2)

def main():
    vectors = [f"{VECT_PREFIX}/{i['name']}" for i in list_folder(VECT_PREFIX) if is_vector(i["name"])]
    rasters = [f"{RAST_PREFIX}/{i['name']}" for i in list_folder(RAST_PREFIX) if is_raster(i["name"])]
    print(f"Found vectors: {vectors}")
    print(f"Found rasters: {rasters}")
    write_layers(vectors, rasters)
    print("✅ Generated: mapfiles/auto_layers.map + mapfiles/layers.json")

if __name__ == "__main__":
    main()
